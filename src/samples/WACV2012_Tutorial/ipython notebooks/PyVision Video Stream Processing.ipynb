{
 "metadata": {
  "name": "PyVision Video Stream Processing"
 }, 
 "nbformat": 2, 
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown", 
     "source": [
      "", 
      "PyVision Video Stream Processing Demonstration", 
      "=====", 
      "", 
      "* Background Subtraction", 
      "* Motion Detection", 
      "* Optical Flow", 
      "* VideoStreamProcessor class"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "import pyvision as pv", 
      "import cv", 
      "import os", 
      "data_dir = os.path.dirname(pv.TAZ_VIDEO)  #in the same directory as the TAZ video there are two others", 
      "taz = pv.TAZ_VIDEO  #tazmanian devil toy", 
      "cars = os.path.join(data_dir,\"toy_car.m4v\")  #toy cars on a carpet", 
      "bug = os.path.join(data_dir,\"BugsSample.m4v\") #a bug in grass"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 3
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Background Subtraction", 
      "-----", 
      "", 
      "PyVision has a few background subtraction methods including:", 
      "", 
      "* Median Filter", 
      "* Approximate Median Filter", 
      "* N-frame Differencing", 
      "* Motion Compensated Frame Differencer"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "#image buffers are required for background models", 
      "imb = pv.ImageBuffer(N=20)", 
      "imb.fillBuffer( pv.Video(bug) )", 
      "", 
      "#get the foreground mask of the \"key frame\" of", 
      "# the buffer using four methods", 
      "mf = pv.MedianFilter(imb)", 
      "amf = pv.ApproximateMedianFilter(imb)", 
      "nfd = pv.FrameDifferencer(imb)", 
      "mcfd = pv.MotionCompensatedFrameDifferencer(imb)", 
      "x1 = mf.getForegroundMask()", 
      "x2 = amf.getForegroundMask()", 
      "x3 = nfd.getForegroundMask()", 
      "x4 = mcfd.getForegroundMask()"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 4
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Where's the bug?", 
      "----"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "#display results in a montage", 
      "imbug = imb.getLast()", 
      "imontage = pv.ImageMontage([imbug, x1,x2,x3,x4], layout=(1,5), tileSize=(320,240))", 
      "imontage.asImage().show( delay=0)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 5
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Motion Detection", 
      "----", 
      "", 
      "Pyvision also has a high-level motion detection class that works with any of the", 
      "background subtraction methods. The motion detector not only finds the foreground", 
      "mask, but also provides a number of annotation options."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "vid_bug = pv.Video(bug) #a bug in grass", 
      "imb = pv.ImageBuffer(N=20)", 
      "imb.fillBuffer(vid_bug) #we have to fill the buffer first...", 
      "", 
      "md = pv.MotionDetector(imageBuff=imb, method=pv.BG_SUBTRACT_AMF)", 
      "for frame in vid_bug:", 
      "    md.detect(frame)", 
      "    if md > -1: ", 
      "        img = md.getAnnotatedImage(showRects=True, showContours=True, showConvexHulls=True)", 
      "        img.show(\"Motion Detection Sample\", delay=40)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 6
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "cv.DestroyWindow(\"Motion Detection Sample\")"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 7
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "If the camera exhibits some ego motion, the **motion-compensated frame differencer**", 
      "may be the way to go."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "vid_car = pv.Video(cars)", 
      "", 
      "imb1 = pv.ImageBuffer(N=4)  #fast motion, so use smaller buffer", 
      "imb2 = pv.ImageBuffer(N=4)", 
      "while not imb1.isFull():", 
      "    f = vid_car.next()", 
      "    imb1.add(f)", 
      "    imb2.add(f)", 
      "", 
      "md1 = pv.MotionDetector(imageBuff=imb1, method=pv.BG_SUBTRACT_MCFD)", 
      "md2 = pv.MotionDetector(imageBuff=imb2, method=pv.BG_SUBTRACT_AMF)", 
      "for frame in vid_car:", 
      "    md1.detect(frame)", 
      "    md2.detect(frame)", 
      "    if md2 > -1: ", 
      "        img1 = md1.getForegroundPixels()", 
      "        #md1.annotateFrame(img1, rect_color='red', contour_color=None, flow_color=None)", 
      "        img1.annotateLabel(pv.Point(5,5),\"Motion Comp. Frame Diff.\", color='white', ", 
      "                           background='black', font=18)", 
      "        ", 
      "        img2 = md2.getForegroundPixels() ", 
      "        img2.annotateLabel(pv.Point(5,5),\"Approx Median Filter\", color='white',", 
      "                           background='black', font=18)", 
      "        ", 
      "        imontage = pv.ImageMontage([img1,img2], layout=(2,1), tileSize=(320,240))", 
      "        imontage.asImage().show(\"Motion Detection Comparison\", delay=50)", 
      "        "
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 8
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "cv.DestroyWindow(\"Motion Detection Comparison\")"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 9
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Optical Flow", 
      "----", 
      "", 
      "The pv.OpticalFlow class encapsulates LK optical flow computations and is", 
      "easy to apply to videos."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "vid_car = pv.Video(cars)", 
      "of = pv.OpticalFlow()", 
      "for frame in vid_car:", 
      "    of.update(frame)", 
      "    of.annotateFrame(frame)", 
      "    frame.show(window=\"Optical Flow\", delay=50)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 10
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "cv.DestroyWindow(\"Optical Flow\")"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 11
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Video Callback Function Usage", 
      "----", 
      "", 
      "the video.play() method has a parameter where a callback function (or callable object)", 
      "can be specified. </br> This is a good way to encapsulate various computations you wish to", 
      "make on a per-frame basis."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "#callback function to apply to each frame of video", 
      "# in this case, the optical flow object will be passed", 
      "# using a keyword parameter \"of=\"", 
      "def processOF(img, fn, of=None, **kwargs):", 
      "    of.update(img)", 
      "    of.annotateFrame(img)", 
      "    img.show(window=\"Optical Flow\", delay=1)", 
      "", 
      "vid = pv.Video(cars)", 
      "flow_obj = pv.OpticalFlow()", 
      "", 
      "#Note that this way of running optical flow on a video", 
      "# gives the user the pause-and-play interface and annotates", 
      "# the frame number in the upper left (which can be suppressed if desired)", 
      "vid.play(window=None, delay=50, onNewFrame=processOF, of=flow_obj)", 
      "", 
      "", 
      "cv.DestroyWindow(\"Optical Flow\")"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 12
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "cv.DestroyAllWindows()"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 13
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "VideoStreamProcessor (VSP)", 
      "---", 
      "", 
      "A VideoStreamProcessor is an object that can be used as video callback function. </br>", 
      "One use of VSP's is to chain together a set of processes in a modular way"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "vid = pv.Video(cars)", 
      "", 
      "#video writer VSP", 
      "vwVSP = pv.VideoWriterVSP(\"./demo.avi\",fourCC_str=\"XVID\", fps=15, size=(480,272))", 
      "", 
      "#motion detection VSP", 
      "md = pv.MotionDetector(buffSize=5, method=pv.BG_SUBTRACT_MCFD)", 
      "mdVSP = pv.MotionDetectionVSP(md, window=\"Motion\", nextModule=vwVSP)", 
      "", 
      "#VSP that simply annotates the frame number", 
      "fnVSP = pv.FrameNumberVSP(window=None, nextModule=mdVSP)", 
      "", 
      "# frame number annotation -> motion detection -> video writer", 
      "vid.play(window=None, delay=33, annotate=None, onNewFrame=fnVSP)", 
      "", 
      "cv.DestroyAllWindows()"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 14
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "#now we playback the video we just saved using the video writer VSP", 
      "vid = pv.Video(\"./demo.avi\")", 
      "vid.play(window=\"Input\",annotate=None, delay=40)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 15
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "People Detection using OpenCV", 
      "-----", 
      "", 
      "This demonstration shows using the HOG Detector in OpenCV to detect people in an image,", 
      "and how to use the results to annotate the image in pyvision."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "import cv", 
      "import pyvision as pv", 
      "", 
      "UTI_vid = pv.Video(\"./seq3.avi\") #sample video from UT Interactions data set", 
      "", 
      "def detectPeople(img, fn, **kwargs):", 
      "    if fn < 50: return  #no detections in this video until after frame 50", 
      "    ", 
      "    cvim = img.asOpenCV()  #convert to OpenCV format before using OpenCV functions", 
      "    try:", 
      "        found = list(cv.HOGDetectMultiScale(cvim, cv.CreateMemStorage(0)))", 
      "        rect_list = [ pv.Rect(x,y,w,h) for ((x,y),(w,h)) in found]  #python list comprehension", 
      "        for r in rect_list: img.annotateRect(r)", 
      "        img.show(window=\"People Detection\", delay=1)", 
      "    except:", 
      "        #cv.HOGDetectMultiScale can throw exceptions, so catch and try the next frame.", 
      "        pass", 
      "    ", 
      "UTI_vid.play(window=None, delay=10, onNewFrame=detectPeople)", 
      "cv.DestroyWindow(\"People Detection\")"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 16
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "People Detection using PyVision VSPs", 
      "----", 
      "", 
      "We have some VSPs that can do the trick as well. Note the use of **ResizerVSP** to make the window", 
      "smaller, and thus speed up processing of the people detector."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "import pyvision as pv", 
      "import cv", 
      "UTI_vid = pv.Video(\"./seq3.avi\") #sample video from UT Interactions data set", 
      "", 
      "fnVSP = pv.FrameNumberVSP(window=\"People Detection\")", 
      "pdVSP = pv.PeopleDetectionVSP(window=None, nextModule=fnVSP)", 
      "rszVSP = pv.ResizerVSP(new_size=(320,240), window=None, nextModule=pdVSP)", 
      "", 
      "#input -> resized -> people detected -> frame number annotated", 
      "UTI_vid.play(window=None, delay=10, onNewFrame=rszVSP)", 
      "", 
      "cv.DestroyWindow(\"People Detection\")"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 17
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "cv.DestroyAllWindows()"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 6
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": "&nbsp;"
    }
   ]
  }
 ]
}